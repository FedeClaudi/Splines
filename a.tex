\section*{Introduction}
\paragraph{}
Networks of neurons can be viewed as dynamical systems in which the joint activity of all units is a state that
represents the information stored in the network, and its dynamics represent computations \mycitep{Vyas2020-pw,
Sussillo2014-mo}.
Under this \textit{computation through dynamics} perspective, understanding neuronal computation requires describing the
dynamics of neural networks and how these are determined by their connectivity structure \mycitep{Schaeffer2020-qv,
Finkelstein2021-gb}. Neural dynamics are often conceptualized as trajectories in an $n$-dimensional vector space - the
state space - in which the distance along each dimension represents the firing rate of individual neurons.
Recent work suggests that, in both biological and artificial neural networks, such neural trajectories are often
confined to a lower dimensional subspace of state space \mycitep{Gao2015-ui, Gao2017-rk, Russo2018-me, Gallego2017-bn,
Maheswaranathan2019-ux, Khona2021-vn, Beiran2021-hl}, and occasionally, to a neural manifold with additional topological
structure \mycitep{Kim2017-no, Gardner2021-mb, Chaudhuri2019-yh}.
It has been further hypothesized that the geometry and topology of these low dimensional neural manifolds are linked in
a fundamental way to the computations carried out by the network \mycitep{Maheswaranathan2019-ux, Gao2017-rk,
Jazayeri2021-tn, Darshan2021-dv, Chung2021-hm, Pollock2020-hb, Duncker2021-ap}.
This view therefore emphasizes that understanding how network connectivity gives rise to structured neural dynamics is a
key goal towards explaining neural computations.

\textcolor{ForestGreen}{Alongside ongoing experimental work, computational efforts aim to develop tools for probing the
casual link between network connectivity, dynamics and computation. To this end, artificial Recurrent Neural Networks
(RNNs) are ideal test beds for novel ideas since they can be trained to solve a variety of tasks similar to those
employed in experimental neuroscience (often displaying dynamics similar to those recorded experimentally in behaving
animals, \mycitep{Barak2017-uh, Turner2021-eb, Schaeffer2020-qv}), and their connectivity structure and dynamics are
perfectly known facilitating the application of tools from dynamical systems theory to reverse-engineer the network
dynamics carrying out computation \mycitep{Sussillo2014-mo, Sussillo2013-ey, Mastrogiuseppe2018-ss, Barak2017-uh,
Schaeffer2020-qv}}. An approach alternative to the reverse-engineering one is to develop general algorithms for directly
constructing networks with dynamics that are targeted to a pre-selected manifold in an effort to produce a deeper
understanding of how connectivity determines dynamics.
\textcolor{ForestGreen}{Recent work in this direction led to methods for engineer low-rank RNNs with targeted dynamics
\mycitep{Mastrogiuseppe2018-ss, Beiran2020-tf}, RNNs displaying manifold attractor dynamics \mycitep{Darshan2021-dv} and
general algorithms for producing manifold-targeted RNNs \mycitep{Pollock2020-hb, Biswas2020-gi}. Additionally, the
Neural Engineering Framework \mycitep{Eliasmith2004-fh, Barak2021-ko, Eliasmith2005-gx} aims to develop a general,
theory-grounded, framework for engineering targeted neural networks (both feed forward and recurrent, with rate and
spiking units)}.

\textcolor{ForestGreen}{The algorithm described in \mycite{Pollock2020-hb} (Embedding Manifolds with Population-level
Jacobians (EMPJ)) can, in principle, be used to investigate a large number of questions of interested in neuroscience,
making it a particularly promising approach. In practice, however, application of EMPJ to problems with complex,
non-linear, target manifolds remains not trivial, thus limiting the set of problems to which it can easily be applied
to. Briefly, EMPJ takes a set of vectors tangent to the target manifold} to build a system of equations that yields the
connectivity matrix for a network with dynamics that lay on the target manifold. Tangent vectors play a dual role in
EMPJ: by being tangent to the target manifold they confine the RNN dynamics to it, and their orientation and magnitude
dictate the direction and speed of the on-manifold \textcolor{ForestGreen}{(i.e., along-side the manifold's surface)}
RNN dynamics.
\textcolor{ForestGreen}{Thus, producing specific on-manifold dynamics with EMPJ requires that a set of precisely
oriented tangent vectors be identified (e.g., tangent vectors at points in the neighborhood of an attractor state should
be oriented towards that state to drive the dynamics towards it, see \fig{fig:F1}B). Computing the required tangent
vectors is complicated by the fact that, for a sufficiently high dimensional state space, there's an infinite number of
ways to embed a low dimensional manifold and the position and orientation of the tangent vectors depends on the choice
of embedding (\fig{fig:F1}A). Furthermore, the tangent vectors need to be computed anew when a different embedding
is selected or if the dimensionality of the state space is changed (e.g. to produce networks with different number of
units), requiring that additional effort be put into computing tangent vectors. All together, this restricts the set of
problems to which EMPJ can easily be applied to to those for which computing tangent vectors on the target manifold is
relatively simple. 
In this work we aim to address this limitation by demonstrating how to utilize tools from topology and differential
geometry to facilitate the task of computing tangent vectors for use with RNN engineering algorithms such as EMPJ.
Briefly, we show how tangent vectors can be computed on a topological manifold prior to its embedding in a high
dimensional state space (\fig{Fig:1}A). This approach offers two key advantages: first, on-manifold dynamics are generally
chosen to match the desired dynamics of latent task variables  \mycitep{Pollock2020-hb, Kao2019-hv, Jazayeri2021-tn,
Maheswaranathan2019-ux} which are generally low dimensional and match the topology of the target dynamics manifold 
while the dimensionality of the state space the manifold is embedded in is higher and depends on the number of units in the network.
It's thus best to define the target on-manifold dynamics on the canonical manifold prior to its embedding.
Second, once tangent vectors have been computed on a topological manifold, the corresponding vectors on any embedding of the manifold in a
larger space can be computed with minimal additional effort, simplifying the task of computing tangent vectors for EMPJ and
reducing the requirements for additional effort when the manifold embedding or embedding space dimensionality are changed.
Here, we describe how to define tangent vectors on a topological manifolds and obtain the corresponding vectors on an embedded
manifold making use of tools from topology and differential geometry. While these ideas are well established and 
routinely used in other fields (e.g., physics and engineering), they are relatively new to neuroscience. 
Yet, we believe, differential geometry offers a powerful conceptual framework for describing the geometry of neural dynamics manifolds
across networks (artificial and biological) and tasks, promising to facilitate the study of common principles underlying 
neural network function. We thus describe the mathematical tools used in this work in detail and show how they can used to compute
tangent vectors on target manifolds. We test the accuracy... XXX
}


% --------------------------------- Figure 1 --------------------------------- %
\begin{center}
\includegraphics[width=14cm]{figures/F1.png}
\captionof{figure}{\textbf{Topological manifolds and tangent vectors.}
\textcolor{ForestGreen}{
\textbf{A.} Left, the topological manifold \mrtwo with a schematic representation of tangent vectors at a point. Right,
embeddings of \mrtwo in \mrthree.
\textbf{B.} Tangent vector fields. A tangent vectors field on the topological manifold \mrtwo (top) and embedded in
\mrthree (bottom).
\textbf{C.} Tangent vectors. Left, a topological manifold $\M$ and a chart $(x, U)$ containing a point $p$ with tangent
vectors through it. The basis functions $f_i$ through $x(p)$ in the chart's local coordinates system $x(U)$ are shown.
Right, visualization of the manifold and tangent vectors embedded in \mrthree (bottom) and the relationship between
tangent vectors as curves through a point on the manifold and $n$-dimensional vectors in the tangent plane (top).
}}\label{fig:F1}
\end{center}